{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECE 447 Project\n",
    "\n",
    "## Authors\n",
    "Kyle Bricker - 1578023  \n",
    "Max Eberle - 1576215  \n",
    "Dhruv Pranlal - 1628666"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix,ConfusionMatrixDisplay,accuracy_score\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"zoo.csv\")\n",
    "target_names = list(set(df[\"type\"])) # gets array of zoo animal types\n",
    "# target_names = [item.strip('\\'').replace('b\\'','') for item in target_names]\n",
    "# print(target_names)\n",
    "\n",
    "\n",
    "# df.type.replace({'b\\'reptile\\'':'reptile','b\\'bird\\'':'bird','b\\'amphibian\\'':'amphibian','b\\'insect\\'':'insect','b\\'fish\\'':'fish','b\\'mammal\\'':'mammal','b\\'invertebrate\\'':'invertabrate'}, inplace=True)\n",
    "df.type.replace({'b\\'reptile\\'':0,'b\\'bird\\'':1,'b\\'amphibian\\'':2,'b\\'insect\\'':3,'b\\'fish\\'':4,'b\\'mammal\\'':5,'b\\'invertebrate\\'':6}, inplace=True)\n",
    "df.hair.replace({'b\\'true\\'':1, 'b\\'false\\'':0}, inplace=True)\n",
    "df.feathers.replace({'b\\'true\\'':1, 'b\\'false\\'':0}, inplace=True)\n",
    "df.eggs.replace({'b\\'true\\'':1, 'b\\'false\\'':0}, inplace=True)\n",
    "df.milk.replace({'b\\'true\\'':1, 'b\\'false\\'':0}, inplace=True)\n",
    "df.airborne.replace({'b\\'true\\'':1, 'b\\'false\\'':0}, inplace=True)\n",
    "df.aquatic.replace({'b\\'true\\'':1, 'b\\'false\\'':0}, inplace=True)\n",
    "df.predator.replace({'b\\'true\\'':1, 'b\\'false\\'':0}, inplace=True)\n",
    "df.toothed.replace({'b\\'true\\'':1, 'b\\'false\\'':0}, inplace=True)\n",
    "df.backbone.replace({'b\\'true\\'':1, 'b\\'false\\'':0}, inplace=True)\n",
    "df.breathes.replace({'b\\'true\\'':1, 'b\\'false\\'':0}, inplace=True)\n",
    "df.venomous.replace({'b\\'true\\'':1, 'b\\'false\\'':0}, inplace=True)\n",
    "df.fins.replace({'b\\'true\\'':1, 'b\\'false\\'':0}, inplace=True)\n",
    "df['tail'].replace({'b\\'true\\'':1, 'b\\'false\\'':0}, inplace=True)\n",
    "df.domestic.replace({'b\\'true\\'':1, 'b\\'false\\'':0}, inplace=True)\n",
    "df.catsize.replace({'b\\'true\\'':1, 'b\\'false\\'':0}, inplace=True)\n",
    "\n",
    "X=df.drop(columns=['type', 'animal'])\n",
    "y=df['type']\n",
    "target_names = ['Reptile','Bird','Amphibian','Insect','Fish','Mammal','Invertebrate']\n",
    "target_labels = [0,1,2,3,4,5,6]\n",
    "print(target_names)\n",
    "feature_names = list(X.columns)\n",
    "print(feature_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describing Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing Complete Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Number of Each Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_names = y.copy()\n",
    "for i in range(0,7):\n",
    "    y_names[y_names == i] = target_names[i]\n",
    "print(y_names.value_counts())\n",
    "\n",
    "plt.figure(figsize = (12,8))\n",
    "ax = sns.countplot(\n",
    "        x='type', \n",
    "        data=df,\n",
    "        order=df['type'].value_counts().index,\n",
    "        palette='Spectral_r'\n",
    "        )\n",
    "for p in ax.patches:\n",
    "        ax.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.3, p.get_height()+0.5))\n",
    "x_labels = []\n",
    "for text in ax.get_xticklabels():\n",
    "        x_labels.append(target_names[int(text.get_text())])\n",
    "ax.set_xticklabels(x_labels)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_corr = df.corr(method = 'pearson')\n",
    "sns.heatmap(data_corr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get testing and training values for the model\n",
    "X_train, X_test, Y_train, Y_test = train_test_split( X.values , y , test_size = 0.3, random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "import statistics\n",
    "\n",
    "# Bootstrapping function\n",
    "def bootstrap(model,X_train,n):\n",
    "    iterations = n # number of bootstrap samples\n",
    "    size = int(len(X_train)*0.5) # size of bootstrap sample\n",
    "    #stats = list()\n",
    "    vals = []\n",
    "    for i in range(iterations):\n",
    "        train = resample(X_train, n_samples=size) # sampling with replacement, unused data is used for test data\n",
    "        test = np.array([x for x in X_train if x.tolist() not in train.tolist()]) # data not used by training sample is used here\n",
    "        model.fit(train[:,:-1], train[:,-1]) # train model - model.fit(X_train,y_train) \n",
    "        predictions = model.predict(test[:,:-1]) # make predictions - model.predict(X_test)\n",
    "        score = accuracy_score(test[:,-1], predictions) # score predictions\n",
    "        #print(round(score,3))\n",
    "        #stats.append(score)\n",
    "        vals += [score] # store score for average\n",
    "    print(\"The bootstrap score is:\", round(statistics.mean(vals),3)) # print average score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=5)\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "plt.figure(figsize=(14,10))\n",
    "tree.plot_tree(clf, feature_names=feature_names, class_names=target_names, fontsize=10)\n",
    "plt.show()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test, Y_pred, target_names=target_names, labels=target_labels))\n",
    "dt_cross = cross_val_score(clf,X,y,cv=5)\n",
    "print(\"The 5-fold cross validation scores are:\")\n",
    "dt_cross_df = pd.DataFrame(data={'Score': dt_cross})\n",
    "print(dt_cross_df.round(3))\n",
    "bootstrap(clf,X.to_numpy(),200)\n",
    "\n",
    "cm = confusion_matrix(Y_test, Y_pred, labels=target_labels, )\n",
    "sns.heatmap(cm, yticklabels=target_names, xticklabels=target_names, annot=True);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, the decision tree model obtained an overall accuracy of 90%. It determined that the milk feature was the most important, followed by the feathers and fins features. However, given a 70/30 train/test split, it seemed to struggle with predicting the invertebrate and amphibian targets, and only correctly predicted them 50% of the time. Further, it only managed to predict half of the reptiles and invertebrates. Since there were only three false predictions total, this was likely due to a bad split from there only being 101 values in the dataset. Changing the split to 60/40 train/test improved on this by resulting in a higher overall accuracy of 93%, but the same three missclassifications were made. To check for overfitting, 5-fold cross validation was used, which resulted in scores of 0.952, 0.850, 0.900, 0.850, and 0.950, supporting the overall accuracy. However, due to the small size of the dataset, bootstrapping was attempted, which returned a score of 0.61. Since bootstrapping uses resampling, this value may be biased. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = LogisticRegression(max_iter = 101)\n",
    "model_lr.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_lr = model_lr.predict(X_test)\n",
    "cr_lr = classification_report(Y_test, Y_pred_lr, target_names=target_names)\n",
    "print(cr_lr)\n",
    "logreg_cross = cross_val_score(model_lr,X,y,cv=5)\n",
    "print(\"The 5-fold cross validation scores are:\")\n",
    "logreg_cross_df = pd.DataFrame(data={'Score': logreg_cross})\n",
    "print(logreg_cross_df.round(3))\n",
    "bootstrap(model_lr,X.to_numpy(),100)\n",
    "\n",
    "cm = confusion_matrix(Y_test, Y_pred_lr, labels=target_labels,)\n",
    "sns.heatmap(cm, yticklabels=target_names, xticklabels=target_names, annot=True);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, the logistic regression model obtained an overall accuracy of 97% with only one false prediction, mislabeling a reptile as a fish. However, since the reptile target only had two values, it received a recall of 50%. To mitigate this, the train/test split was changed from 70/30 to 60/40, but the logistic regression model continued making the same incorrect prediction.  The change in the train/test split also gave the model more values to test, of which it correctly predicted all of them, increasing the overall accuracy to 98%. 5-fold cross validation was used on the model, and returned values of 1.00, 0.95, 0.90, 0.95, and 0.95, which support the overall accuracy. Since the dataset used only contains 101 values per feature, bootstrapping was attempted to obtain another performance measure. This returned 0.643, which could indicate that the other accuracy measures are skewed, but more likely means that the bootstrapping function was biased.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the decision tree and the logistic regression models, it appears that the logistic regression obtained better results. With a 97% overall accuracy compared to the decision tree's accuracy of 90%, the linear regression model was able to correctly predict all the targets in the test set except for one. While the decision tree missclassified a reptile as an amphibian, an invertebrate as an insect, and an insect as an invertebrate, the logistic regression interestingly only mixed up a reptile for a fish. Considering the 5-fold cross validation scores, the logistic regression model exceeded those of the decision tree, and its bootstrap score was higher as well. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.drop([\"animal\", \"type\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(\n",
    "    init=\"k-means++\",\n",
    "    n_clusters=7,\n",
    "    n_init=12,\n",
    "    max_iter=5000,\n",
    "    random_state=35\n",
    ")\n",
    "kmeans.fit(df_cleaned);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = kmeans.fit_predict(df_cleaned)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = [[], [], [], [], [], [], []] # array of 7 arrays for our 7 clusters\n",
    "names = df[\"animal\"]\n",
    "\n",
    "for idx in range(len(labels)):\n",
    "    clusters[labels[idx]].append((names[idx], target_names[y[idx]]))\n",
    "\n",
    "for ct in range(7):\n",
    "    print(f'\\nCluster {ct}:')\n",
    "    print(clusters[ct])\n",
    "    types = [x[1] for x in clusters[ct]]\n",
    "    for name in target_names:\n",
    "        if types.count(name) > 0:\n",
    "            print(f\"{name}: {types.count(name)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output above, each cluster has the number of occurrences of each class that it contains printed below it. This shows that the bird class has the most definitive data, since all the birds are contained in cluster 4. Looking at cluster 5, all the points corresponding to the fish class are contained, but there are also three mammal points and one reptile. The mammal points include the dolphin, porpoise, and seal, while the reptile point is the seasnake. Since all these animals have similar feature data to fish, it is understandable how the algorithm would have sorted them into this cluster. On the other hand, cluster 6 is the only other cluster that contains points from three different classes: reptile, amphibian, and invertebrate. The features' data for these points, however, do not correlate well with eachother, which shows that the K-means algorithm is not well equipped for this data. \n",
    "\n",
    "While cluster 3 only contains the mammal class, it doesn't contain all the points and shares some with cluster 2. Looking at the feature data, another shortcoming of the K-means algorithm is revealed as the points in cluster 2 have similar features to those in cluster 3. Thus, it is unclear why the algorithm split the mammal points between these two clusters. Similarly, the algorithm struggled with the invertebrate class, as it was split across clusters 0, 1 and 6. Since the invertebrate class shares features with many of the other classes, it is clear why the algorithm had trouble defining them separately. Cluster 0 is semi-successful as it contains all the points of the insect class, but it also has some invertebrates. Again, this is somewhat understandable as the invertebrate points in cluster 0 share most features with the insects, with the only main exception being the aquatic feature. \n",
    "\n",
    "The results of K-means clustering with this dataset show that it is not well suited for discrete values, rather it is inteded to be used on datasets with continuous values. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the nature of this dataset is discrete (most features have only two unique values), the logistic regression model would offer better performance. This is further reflected in the classification reports, 5-fold cross validation scores, and bootstrap scores of both models. In their accuracy with the zoo dataset, the decision tree misclassified three animals, while the logistic regression model only missclassified one. Despite this, further testing and validation should be done on both of these models to ensure the results generated here are not inflated. Since this dataset only contains 101 values for each feature, there is a chance that overfitting occurred. \n",
    "\n",
    "A K-means clustering algorithm was also tested on this dataset, but had meager performance compared to the other models. Since K-means algorithms are intended for continuous data, the discrete data from this dataset resulted in many classes being split over multiple clusters. The algorithm particularly struggled with the invertebrate, mammal, and reptile classes, although seemed to handle the bird and insect classes without issue. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
